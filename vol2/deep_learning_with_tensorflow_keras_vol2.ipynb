{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配降下法\n",
    "与えられた訓練データ  \n",
    "  \n",
    "$$\n",
    "D = \\{ (x_{1}, d_{1}), (x_{2}, d_{2}), ... ,  (x_{N}, d_{N})  \\}\n",
    "$$\n",
    "  \n",
    "を用いて計算された誤差関数 $E(w)$について、ネットワークのパラメータ(重みとバイアス)$w$について最小化することが、  \n",
    "順伝搬型ニューラルネットの学習の目的になります。  \n",
    "  \n",
    "つまり、一般的には下記の誤差関数を扱うことになります。  \n",
    "  \n",
    "$$\n",
    "E(w)=\\frac{1}{2}\\sum_{n=1}^{N}\\parallel d_{n} - y(x_{n}, w) \\parallel ^{2}\n",
    "$$\n",
    "  \n",
    "多値分類(多クラス分類問題)についての誤差関数については下記のようになります。  \n",
    "  \n",
    "$$\n",
    "E(w)=-\\sum_{k=1}^{N}\\sum_{k=1}^{K} d_{nk} \\log y_{k}(x_{n}, w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習のゴール\n",
    "選んだ$E(w)$に対して最小値を与える$w=argmin_{w}E(w)$を求めることですが、前回の内容のように簡単には最小値を求めることができません。  \n",
    "いくつもの極小値から、最小値の候補となる極小値を見つけ出すことが考えられますが、見つけた極小値が本当に最小値かどうかを評価する必要があります。  \n",
    "たまたま見つけた極小値が、$E(w)$の大局的な最小値である可能性はほぼないです。  \n",
    "  \n",
    "したがって、何らかの初期値を与えて『繰り返し』$w$を更新して反復計算を行います。  \n",
    "もっとも簡単な方法が、**勾配降下法**(gradient descent method)となります。勾配降下法の**勾配**(gradient)とは、\n",
    "  \n",
    "$$\n",
    "  \\nabla E = \\frac{\\partial E}{\\partial w}  =\\left[\n",
    "    \\frac{\\partial E}{\\partial w_{1}} \\cdot \\cdot \\cdot \\frac{\\partial E}{\\partial w_{M}}\n",
    "  \\right]^{T}\n",
    "$$\n",
    "  \n",
    "勾配降下法は、現在の$w$を、負の勾配方向$- \\nabla E$に少し動かして...という処理を何度も繰り返し行います。  \n",
    "現在の重みを、$w^{t}$, 動かした後の重みを$w^{t+1}$とすると、\n",
    "  \n",
    "$$\n",
    "w^{t+1} = w^{t} - \\epsilon \\nabla E\n",
    "$$\n",
    "  \n",
    "この$\\epsilon$を、**学習係数**(ステップ幅)といいます。  \n",
    "学習係数の決定は大変重要な問題で、学習がうまくいくかどうかの要因の１つになります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確率的勾配降下法\n",
    "全訓練サンプル$n=1, 2, ... , N$に対して計算される誤差関数$E(w)$について最小化すること、これを前述しましたが、  \n",
    "このとき回帰やクラス分類のどれであっても$E(w)$は各サンプル1個だけについて計算される誤差$E_{n}$の和として、  \n",
    "  \n",
    "$$\n",
    "E(w) = \\sum_{n=1}^{N}E_{n}(w)\n",
    "$$\n",
    "  \n",
    "と与えれらます。  \n",
    "$w$の更新式として、$w^{t+1} = w^{t} - \\epsilon \\nabla E$では、この$E(w)$を用いています。  \n",
    "この方法を、一般的に**バッチ学習**(batch learning)と呼びます。※エポック学習(epoch learning)ともいいます  \n",
    "  \n",
    "上記の場合は、**すべての訓練データ**を考慮していますが、この方法以外に、サンプルの一部、極端にはサンプルの１つだけを用いて  \n",
    "パラメータの更新を行うことがあります。これを**確率的勾配降下法**(stochastic gradient descent)といい、頭文字をとって**SGD**と呼ばれています。  \n",
    "  \n",
    "この方法では、$w$の更新は１つのサンプル$k$について計算される誤差関数$E_{k}(w)$の勾配$\\nabla E_{k}$を計算し、  \n",
    "  \n",
    "$$\n",
    "w^{t+1} = w^{t} - \\epsilon \\nabla E_{k}\n",
    "$$\n",
    "  \n",
    "のように$w$を更新します。次の$w^{t+1}$の更新の際は、別のサンプル$k^{'}$を取り出して、これを用いて同様に勾配$\\nabla E_{k^{'}}$を評価し$w$を更新します。  \n",
    "このようにしてサンプルを毎回取り替えて、$w$を更新していきます。  \n",
    "  \n",
    "バッチ学習の勾配降下法に対して、確率的勾配降下法にはいくつかの長所があるため、ディープラーニングの学習では確率的勾配降下法を利用するのが一般的です。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチの利用\n",
    "規模が大きくなってくると、特にニューラルネットワークの学習には大きなコスト(計算時間)を要します。  \n",
    "そこで計算を効率よくするために、計算機がもつ並列計算資源の利用が不可欠となってきます。  \n",
    "そのために、サンプル一つ単位で重みを更新するのではなく、少数のサンプルの集合を**ひとまとめ**にして、その単位で重みを更新します。  \n",
    "  \n",
    "このひとまとめの集合を、**ミニバッチ**(mini-batch)といいます。  \n",
    "  \n",
    "具体的には、下記のような処理をします。\n",
    "  \n",
    "・まず１つのミニバッチを$D_{t}$と書くことにします  \n",
    "※少数のサンプルの集合を指していて、$t$回目の更新ごとにそのサンプル集合が変わることを示しています  \n",
    "  \n",
    "・$D_{t}$の含むサンプルに対する誤差  \n",
    "  \n",
    "$$\n",
    "E_{t}(w) = \\frac{1}{N_{t}}\\sum_{n \\in D_{t}}E_{n}(w)\n",
    "$$\n",
    "  \n",
    "を計算して、その勾配の方向にパラメータを更新します。  \n",
    "$N_{t}=\\mid D_{t} \\mid$はこのミニバッチが含むサンプル数となります。  \n",
    "  \n",
    "このときに、$E_{t}(w)$を$N_{t}$で正規化しておくと、ミニバッチのサンプルのサイズ(サンプル数)を変えたときに、  \n",
    "それに合わせて学習係数を調整しなければならない面倒くささを低減することができます。  \n",
    "  \n",
    "確率的降下勾配法のメリットと並列計算資源のトレードオフを考えて、うまく設定します。  \n",
    "大体ミニバッチのサイズが、10~100(50〜256)が一般的ですが、目的とゴールによって様々。  \n",
    "  \n",
    "ミニバッチのサイズを大きくすればするほど、ミニバッチ間で計算される勾配のばらつきが小さくなり、  \n",
    "$w$の更新量が安定するので、学習係数$\\epsilon$を大きくでき、それだけ学習が速く進むことになります。  \n",
    "しかし一方で、ミニバッチサイズを$N$倍しても、$\\epsilon$を$N$倍大きくすることはできないので、結果としてトータルの計算速度は低下します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 汎化性能と過学習\n",
    "ここまでは、訓練データに対する誤差(誤差関数の値)を小さくすること、最小化することを考えてきました。  \n",
    "学習の本当の目的は、与えられた訓練データではなくて、これから与えられるはずの『まだ知らない』データ$X$について正しい推定ができることです。  \n",
    "  \n",
    "訓練データに対する誤差を**訓練誤差**(training error)、『まだ知らない』データ、正しく言えばサンプルの母集団に対する誤差の期待値を、  \n",
    "**汎化誤差**(generalization error)といいます。  \n",
    "  \n",
    "汎化誤差を小さくすることがベストですが、汎化誤差は統計的な期待値で、訓練誤差のようには計算できません。(例えば、繰り返して訓練できない)  \n",
    "そこで訓練データとは別のサンプルデータを用意します。このサンプルデータに対して訓練誤差と同じ方法で計算される誤差を、  \n",
    "汎化誤差の\"目安\"とします。※この目安を、仮にテスト誤差とします  \n",
    "  \n",
    "訓練誤差は一般的に、パラメータを更新する後に単調に減少して収束していきます。(学習が進んでいるから)  \n",
    "一方で、テスト誤差は学習の前半では訓練誤差とほぼ同じように減少しますが、学習の後半では徐々に解離していきます。  \n",
    "理想は、このテスト誤差が訓練誤差とよく近似できていることです。(後述)  \n",
    "  \n",
    "このときに、学習中盤以降に、訓練誤差とテスト誤差を大きく解離していくパターンがあり、  \n",
    "このパターンを、**過学習(over learning)**(過適合:over fitting)といいます。  \n",
    "  \n",
    "パラメータ更新に伴って、訓練誤差に対してテスト誤差が大きくなっていくと、むしろそれ以上の訓練・学習は有効ではないために、  \n",
    "早期に学習を切り上げるのがベターです。そのとき、**早期打ち切り**(early stopping)を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過学習の回避\n",
    "**ドロップアウト**は、多層ニューラルネットのユニットを確率的に選別して学習する方法です。  \n",
    "多くの場合、大変良い結果が得られるために現在広く扱われています。ドロップアウトは、ネットワークの学習過程と学習後の推論過程を、  \n",
    "以下のように修正していきます。  \n",
    "  \n",
    "・学習時、中間層の各層と入力層のユニットを決まった割合$p$でランダムに選出する(選出されたもの以外は無視)  \n",
    "・選出されたユニットだけのニューラルネットで学習を進める  \n",
    "・訓練サンプルをネットワークに順伝搬計算を行って、誤差を求め、逆伝搬計算を行って誤差の勾配を計算し、重みを更新  \n",
    "  \n",
    "※ミニバッチを用いている場合、ミニバッチ単位でユニットを選びなおします。  \n",
    "ユニットの選出確率は、層ごとに変化させても問題ありません。  \n",
    "  \n",
    "学習終了時の推論時には、すべてのユニットを使って順伝搬計算を行います。  \n",
    "ただし、ドロップアウトで無効化の対象とした層のユニットは、すべて一律に出力を$p$倍します。  \n",
    "  \n",
    "ドロップアウトの目的は、学習時にネットワークの自由度を強制的に小さくし、過学習を避けることです。  \n",
    "ドロップアウト時のネットワークを複数独立に訓令し、推論時にそれらの結果を平均するのと同じ効果があります。  \n",
    "\n",
    "**モメンタム(モーメンタム)**(momentum)という方法もあり、勾配降下法の収束性能を向上させる方法となります。  \n",
    "これは重みの修正量に、ミニバッチ$t-1$に対する重みの修正量を$\\delta w^{t-1} \\equiv w^{t} - w^{t-1}$とすれば、ミニバッチの更新を  \n",
    "  \n",
    "$$\n",
    "w^{t+1} = w^{t} - \\epsilon \\nabla E_{t} + \\mu \\delta w^{t-1}\n",
    "$$\n",
    "  \n",
    "と定義します。\n",
    "$\\mu$はハイパーパラメータの一つになり、通常は、0.5~0.9の範囲から選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kerasの実装編"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 704\n",
      "Trainable params: 704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前回の順伝搬型ニューラルネットに、SGDを用いて再度学習させてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST データセットを取り込む\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 変換前：28 x 28 の2次元配列 x 60,000\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28*28の２次元配列を、784要素の1次元配列に変換する＆256階調を[0, 1]に正規化\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255\n",
    "X_test  = X_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~9の数字を、10次元で表現する\n",
    "y_train_array = np_utils.to_categorical(y_train, 10)\n",
    "y_test_array  = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの箱(空箱)\n",
    "model_non_drop_out_with_SGD = Sequential()\n",
    "\n",
    "# 入力層\n",
    "# - ノード数：512\n",
    "# - 入力：784次元\n",
    "# - 活性化関数：relu\n",
    "model_non_drop_out_with_SGD.add(Dense(512, input_dim=784))\n",
    "model_non_drop_out_with_SGD.add(Activation('relu'))\n",
    "\n",
    "# 隠れ層\n",
    "# - ノード数：512\n",
    "# - 活性化関数：relu\n",
    "model_non_drop_out_with_SGD.add(Dense(512))\n",
    "model_non_drop_out_with_SGD.add(Activation('relu'))\n",
    "\n",
    "# 出力層\n",
    "# - ノード数：10\n",
    "# - 活性化関数：softmax\n",
    "model_non_drop_out_with_SGD.add(Dense(10))\n",
    "model_non_drop_out_with_SGD.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_non_drop_out_with_SGD.compile(loss='categorical_crossentropy',\n",
    "                                    optimizer=sgd,\n",
    "                                    metrics=['accuracy']\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデルの要約を出力\n",
    "model_non_drop_out_with_SGD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.4241 - accuracy: 0.8856 - val_loss: 0.2208 - val_accuracy: 0.9375\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1930 - accuracy: 0.9436 - val_loss: 0.1568 - val_accuracy: 0.9532\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1416 - accuracy: 0.9600 - val_loss: 0.1236 - val_accuracy: 0.9635\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1113 - accuracy: 0.9679 - val_loss: 0.1072 - val_accuracy: 0.9681\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0905 - accuracy: 0.9742 - val_loss: 0.0939 - val_accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0757 - accuracy: 0.9784 - val_loss: 0.0894 - val_accuracy: 0.9732\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0645 - accuracy: 0.9819 - val_loss: 0.0787 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 0.0779 - val_accuracy: 0.9756\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.0705 - val_accuracy: 0.9781\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0409 - accuracy: 0.9887 - val_loss: 0.0672 - val_accuracy: 0.9782\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 0.0667 - val_accuracy: 0.9798\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.0656 - val_accuracy: 0.9792\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0268 - accuracy: 0.9935 - val_loss: 0.0647 - val_accuracy: 0.9801\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0231 - accuracy: 0.9948 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 0.0652 - val_accuracy: 0.9803\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 0.0598 - val_accuracy: 0.9810\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0152 - accuracy: 0.9974 - val_loss: 0.0623 - val_accuracy: 0.9813\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: 0.0602 - val_accuracy: 0.9808\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.0617 - val_accuracy: 0.9818\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.0610 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x136d3be48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "# - バッチサイズ：128\n",
    "# - 学習の繰り返し回数：20\n",
    "model_non_drop_out_with_SGD.fit(X_train, y_train_array,\n",
    "                       batch_size=128,\n",
    "                       epochs=20,\n",
    "                       verbose=1,\n",
    "                       validation_data=(X_test, y_test_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.060966521442710656\n",
      "Test accuracy : 0.9815000295639038\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "score = model_non_drop_out_with_SGD.evaluate(X_test, y_test_array, verbose=0)\n",
    "print('Test loss :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミニバッチを変更した時の計算速度比較 & Eealy Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early-stopping \n",
    "early_stopping = EarlyStopping(patience=0, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.2271 - accuracy: 0.9312 - val_loss: 0.1266 - val_accuracy: 0.9633\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1114 - accuracy: 0.9663 - val_loss: 0.1070 - val_accuracy: 0.9675\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0781 - accuracy: 0.9759 - val_loss: 0.0979 - val_accuracy: 0.9707\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0603 - accuracy: 0.9807 - val_loss: 0.0883 - val_accuracy: 0.9736\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0971 - val_accuracy: 0.9721\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x10a42aeb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "# - バッチサイズ：10\n",
    "# - 学習の繰り返し回数：20\n",
    "model_non_drop_out_with_SGD.fit(X_train, y_train_array,\n",
    "                                batch_size=10,\n",
    "                                epochs=20,\n",
    "                                verbose=1,\n",
    "                                validation_data=(X_test, y_test_array),\n",
    "                                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.0971373441231146\n",
      "Test accuracy : 0.972100019454956\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "score = model_non_drop_out_with_SGD.evaluate(X_test, y_test_array, verbose=0)\n",
    "print('Test loss :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0712 - val_accuracy: 0.9797\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0682 - val_accuracy: 0.9807\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.0670 - val_accuracy: 0.9803\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0659 - val_accuracy: 0.9806\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0656 - val_accuracy: 0.9807\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.0656 - val_accuracy: 0.9802\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0654 - val_accuracy: 0.9807\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0652 - val_accuracy: 0.9811\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.0650 - val_accuracy: 0.9814\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.0651 - val_accuracy: 0.9814\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x139443390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "# - バッチサイズ：512\n",
    "# - 学習の繰り返し回数：20\n",
    "model_non_drop_out_with_SGD.fit(X_train, y_train_array,\n",
    "                                batch_size=512,\n",
    "                                epochs=20,\n",
    "                                verbose=1,\n",
    "                                validation_data=(X_test, y_test_array),\n",
    "                                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.06507510154138872\n",
      "Test accuracy : 0.9814000129699707\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "score = model_non_drop_out_with_SGD.evaluate(X_test, y_test_array, verbose=0)\n",
    "print('Test loss :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加えてドロップアウトを加えてみる\n",
    "rate = 1-keep_probとなっており、 tensorflowでは、keep_probが扱われ、Kerasは rateになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの箱(空箱)\n",
    "model_with_SGD = Sequential()\n",
    "\n",
    "# 入力層\n",
    "# - ノード数：512\n",
    "# - 入力：784次元\n",
    "# - 活性化関数：relu\n",
    "model_with_SGD.add(Dense(512, input_dim=784))\n",
    "model_with_SGD.add(Activation('relu'))\n",
    "model_with_SGD.add(Dropout(0.1)) # 入力層なので、ドロップアウトを0.9\n",
    "\n",
    "# 隠れ層\n",
    "# - ノード数：512\n",
    "# - 活性化関数：relu\n",
    "model_with_SGD.add(Dense(512))\n",
    "model_with_SGD.add(Activation('relu'))\n",
    "model_with_SGD.add(Dropout(0.5)) # 中間層なので、ドロップアウトを0.5\n",
    "\n",
    "# 出力層\n",
    "# - ノード数：10\n",
    "# - 活性化関数：softmax\n",
    "model_with_SGD.add(Dense(10))\n",
    "model_with_SGD.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_with_SGD.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=sgd,\n",
    "                       metrics=['accuracy']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_SGD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.5022 - accuracy: 0.8494 - val_loss: 0.2160 - val_accuracy: 0.9383\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2289 - accuracy: 0.9330 - val_loss: 0.1529 - val_accuracy: 0.9541\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1729 - accuracy: 0.9494 - val_loss: 0.1251 - val_accuracy: 0.9623\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1389 - accuracy: 0.9592 - val_loss: 0.1092 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1182 - accuracy: 0.9646 - val_loss: 0.0946 - val_accuracy: 0.9722\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.1028 - accuracy: 0.9699 - val_loss: 0.0845 - val_accuracy: 0.9750\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0902 - accuracy: 0.9733 - val_loss: 0.0816 - val_accuracy: 0.9745\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0796 - accuracy: 0.9757 - val_loss: 0.0735 - val_accuracy: 0.9771\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0722 - accuracy: 0.9783 - val_loss: 0.0710 - val_accuracy: 0.9788\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0655 - accuracy: 0.9803 - val_loss: 0.0675 - val_accuracy: 0.9788\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0587 - accuracy: 0.9821 - val_loss: 0.0658 - val_accuracy: 0.9794\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0619 - val_accuracy: 0.9804\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0490 - accuracy: 0.9855 - val_loss: 0.0605 - val_accuracy: 0.9808\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0459 - accuracy: 0.9863 - val_loss: 0.0604 - val_accuracy: 0.9816\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0573 - val_accuracy: 0.9815\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0383 - accuracy: 0.9886 - val_loss: 0.0571 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 0.0575 - val_accuracy: 0.9825\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "# - バッチサイズ：128\n",
    "# - 学習の繰り返し回数：20\n",
    "his = model_with_SGD.fit(X_train, y_train_array,\n",
    "                         batch_size=128,\n",
    "                         epochs=20,\n",
    "                         verbose=1,\n",
    "                         validation_data=(X_test, y_test_array),\n",
    "                         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.05748828273621621\n",
      "Test accuracy : 0.9825000166893005\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "score = model_with_SGD.evaluate(X_test, y_test_array, verbose=0)\n",
    "print('Test loss :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = his.history['loss']\n",
    "val_loss = his.history['val_loss']\n",
    "\n",
    "nb_epoch = len(loss)\n",
    "plt.plot(range(nb_epoch), loss, marker='.', label='loss')\n",
    "plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今回ドロップアウトの恩恵は期待するほどではなかった\n",
    "データが綺麗(特徴を掴みやすい)＆複雑なニューラルネットでもないため？？？  \n",
    "下記の参考リンクでは、ドロップアウトによる過学習(過適合)を抑制できる例があります(参考までに)  \n",
    "[Dropoutによる過学習の抑制](https://medium.com/axinc/dropout%E3%81%AB%E3%82%88%E3%82%8B%E9%81%8E%E5%AD%A6%E7%BF%92%E3%81%AE%E6%8A%91%E5%88%B6-be5b9bba7e89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 余談(参考)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kerasが用意している最適化関数について](https://keras.io/ja/optimizers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**非常に参考となるリンク [勾配降下法の最適化アルゴリズムを概観する](https://postd.cc/optimizing-gradient-descent/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kerasに実装されている最適化アルゴリズムのソースコードの一部](https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L130)\n",
    "  \n",
    "`from keras.mixed_precision import loss_scale_optimizer`  # pylint: disable=g-import-not-at-top  \n",
    "`  all_classes = {`  \n",
    "`      'adadelta': adadelta_v2.Adadelta,`  \n",
    "`      'adagrad': adagrad_v2.Adagrad,`  \n",
    "`      'adam': adam_v2.Adam,`  \n",
    "`      'adamax': adamax_v2.Adamax,`  \n",
    "`      'nadam': nadam_v2.Nadam,`  \n",
    "`      'rmsprop': rmsprop_v2.RMSprop,`  \n",
    "`      'sgd': gradient_descent_v2.SGD,`  \n",
    "`      'ftrl': ftrl.Ftrl,`  \n",
    "`      'lossscaleoptimizer': loss_scale_optimizer.LossScaleOptimizer,`  \n",
    "`      # LossScaleOptimizerV1 deserializes into LossScaleOptimizer, as`  \n",
    "`      # LossScaleOptimizerV1 will be removed soon but deserializing it will`  \n",
    "`      # still be supported.`  \n",
    "`      'lossscaleoptimizerv1': loss_scale_optimizer.LossScaleOptimizer,`  \n",
    "`  }`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**引数に、文字列、例えば\"adam\"とか\"sgd\"とかを設定すれば、バックエンドにあるtensorflowのアルゴリズムを無意識的に扱える**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kerasオプティマイザ(最適化アルゴリズム)にある、SGDの扱い方**  \n",
    "`keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)`  \n",
    "  \n",
    "確率的勾配降下法オプティマイザについて  \n",
    "\n",
    "モーメンタム，学習率減衰，Nesterov momentumをサポートした確率的勾配降下法の引数一覧  \n",
    "  \n",
    "lr: 0以上の浮動小数点数．学習率．  \n",
    "momentum: 0以上の浮動小数点数．モーメンタム．  \n",
    "decay: 0以上の浮動小数点数．各更新の学習率減衰．  \n",
    "nesterov: 真理値. Nesterov momentumを適用するかどうか．  \n",
    "  \n",
    "[Keras SGDのソースコード  ](https://github.com/keras-team/keras/blob/1d49681f825d2d4282719efd27e13aca441b39c2/keras/optimizer_v1.py#L158)  \n",
    "`(中略)`  \n",
    "`  def get_updates(self, loss, params):`  \n",
    "`    grads = self.get_gradients(loss, params)`  \n",
    "`    self.updates = [tf.compat.v1.assign_add(self.iterations, 1)]`  \n",
    "`    lr = self.lr`  \n",
    "`    if self.initial_decay > 0:`  \n",
    "`      lr = lr * (  # pylint: disable=g-no-augmented-assignment`  \n",
    "`          1. /`  \n",
    "`          (1. +`  \n",
    "`           self.decay * tf.cast(self.iterations, K.dtype(self.decay))))`  \n",
    "`    # momentum`  \n",
    "`    moments = self._create_all_weights(params)`  \n",
    "`    for p, g, m in zip(params, grads, moments):`  \n",
    "`      v = self.momentum * m - lr * g  # velocity`  \n",
    "`      self.updates.append(tf.compat.v1.assign(m, v))`  \n",
    "`      if self.nesterov:`  \n",
    "`        new_p = p + self.momentum * v - lr * g`  \n",
    "`      else:`  \n",
    "`        new_p = p + v`  \n",
    "`      # (中略)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
